{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c78f698-6ee6-416e-816b-cf217deaf55b",
   "metadata": {},
   "source": [
    "# Clase 01: Regresion Lineal\n",
    "\n",
    "## Indice\n",
    "- Preambulo\n",
    "    - Linealidad\n",
    "    - Algebra Lineal\n",
    "        - Vectores y Matrices\n",
    "        - Producto interno\n",
    "            - producto interno vs producto punto \n",
    "            - Proyección\n",
    "    - Calculo\n",
    "        - Derivada en una dimension\n",
    "        - Regla de la cadena\n",
    "        - Derivadas parciales\n",
    "        - Gradiente\n",
    "    - Optimización\n",
    "        - Minimización/Maximización a traves de derivadas\n",
    "            - 1 D\n",
    "        - Minimización/Maximización a traves de derivadas parciales\n",
    "            - 2D+ (Gradiente como aparece y se usa)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bbb88",
   "metadata": {},
   "source": [
    "## Preámbulo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3ce21-1e0d-4ff4-b4be-2b4483d02d86",
   "metadata": {},
   "source": [
    "### Linealidad\n",
    "\n",
    "Definición (1):\n",
    "un mapa $f: U \\rightarrow V$, donde $U$ y $V$ son espacios vectoriales, se denomina lineal si cumple con las siguientes propiedades:\n",
    "1. Dado $\\mathbf{x}$, $\\mathbf{y}\\in U$: $f(x+y) = f(x) + f(y)$\n",
    "2. Dado $\\alpha \\in \\mathbb{R}$: $f(\\alpha x) = \\alpha f(x)$\n",
    "3. Corolario: $f(0_{U}) = 0_{V}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fc8922-33ae-42ae-bda7-f792ef3250f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(3 + 2) = f(3) + f(2) =>  10 = 6 + 4\n"
     ]
    }
   ],
   "source": [
    "def f(x: int):\n",
    "    return 2*x\n",
    "\n",
    "print (f\"f(3 + 2) = f(3) + f(2) =>  {f(3+2)} = {f(3)} + {f(2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92113fa-3159-449e-8c27-914d9bc20775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(3 + 2) != f(3) + f(2) =>  25 != 9 + 4\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x**2\n",
    "print (f\"f(3 + 2) != f(3) + f(2) =>  {f(3+2)} != {f(3)} + {f(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263da9cc-6841-4429-8480-d09ccccbd6b3",
   "metadata": {},
   "source": [
    "## Algebra Lineal\n",
    "\n",
    "### Vectores y Matrices\n",
    "\n",
    "Los vectores y matrices son elementos fundamentales del algebra lineal.\n",
    "Para poder desarrollar el curso de Deep Learning necesitaremos responder estas tres preguntas:\n",
    "- como se operan estos objetos?\n",
    "- que propiedades tienen?\n",
    "- que representan en terminos de información? o porque se utilizan para representar datos?\n",
    "\n",
    "Los Vectores y Matrices se utilizan bajo el contexto de espacio vectorial real (Utilizaremos numeros reales $\\mathbb{R}$)\n",
    "Un espacio para considerase vectorial debe cumplir con 10 axiomas:\n",
    "\n",
    "1. Cerradura bajo la suma: si $\\mathbf{x} \\in V$ y  $\\mathbf{y} \\in V$ entonces $\\mathbf{x} + \\mathbf{y} \\in V$\n",
    "2. Asociatividad de la suma de vectores: $(\\mathbf{x} + \\mathbf{y}) + \\mathbf{z} = \\mathbf{x} + (\\mathbf{y} + \\mathbf{z})$\n",
    "3. Existe un vector/matriz $0$ tal que para todo $\\mathbf{x} \\in V$, $\\mathbf{x} + 0 = 0 + \\mathbf{x} = \\mathbf{x}$\n",
    "4. Conmutatividad de la suma de vectores: $\\mathbf{x} + \\mathbf{y} = \\mathbf{y} + \\mathbf{x}$\n",
    "5. Cerradura en la multiplicación de escalares: $\\alpha \\cdot \\mathbf{x} \\in V$, tal que $\\alpha \\in \\mathbb{R}$ y $\\mathbf{x} \\in V$\n",
    "6. Distribucion de suma de escalares: $(\\alpha + \\beta) \\cdot \\mathbf{x} = \\alpha \\cdot \\mathbf{x} + \\beta \\cdot \\mathbf{x}$ tal que $\\alpha$ , $\\beta \\in \\mathbb{R}$, y $\\mathbf{x} \\in V$\n",
    "7. Distribución de suma vectorial: $\\alpha \\cdot (\\mathbf{x} + \\mathbf{y}) = \\alpha \\cdot \\mathbf{x} + \\alpha \\cdot \\mathbf{y}$ tal que $\\alpha \\in \\mathbb{R}$, y $\\mathbf{x}$, $\\mathbf{y} \\in V$\n",
    "8. Distribución de escalares: $\\alpha \\cdot (\\beta + \\gamma) = \\alpha \\cdot \\beta + \\alpha \\cdot \\gamma$ tal que $\\alpha, \\beta, \\gamma \\in \\mathbb{R}$.\n",
    "9. Ley asociativa de multiplicacion por escalares: $\\alpha \\cdot (\\beta \\cdot \\mathbf{x}) = (\\alpha \\cdot \\beta) \\cdot \\mathbf{x}$ tal que $\\alpha, \\beta \\in \\mathbb{R}$, y $\\mathbf{x} \\in V$\n",
    "10. Identico multiplicativo escalar: para cada vector $\\mathbf{x} \\in V$, 1 $\\cdot \\mathbf{x} = \\mathbf{x}$ tal que $\\mathbf{x} \\in V$\n",
    "\n",
    "Ej:\n",
    "- El espacio de vectores de dimension $n$, tambien escrito como $\\mathbb{R}^{n}$ cumple con los axiomas\n",
    "- El espacio de Matrices de dimension $n \\times n$, tambien escrito como $\\mathbb{R}^{n \\times n}$ cumple con los axiomas\n",
    "\n",
    "Las Matrices se pueden pensar como funciones lineales, es decir cumplen con la definicion de linealidad vista anteriormente.\n",
    "La librería de ```python``` que permite trabajar con definiciones y operaciones del álgebra lineal se llama ```numpy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0fa7838-7de9-4ccb-8979-56dbf6338c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x+y) = f(x) + f(y)\n",
      "[[0]\n",
      " [0]]\n",
      "f(x):\n",
      " [[3]\n",
      " [7]]\n",
      "f(y):\n",
      " [[-3]\n",
      " [-7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def f(x: np.array):\n",
    "    m = np.array([[1,2],[3,4]])\n",
    "    return m@x\n",
    "\n",
    "x = np.array([[1], [1]])\n",
    "y = np.array([[-1], [-1]])\n",
    "\n",
    "print(f\"f(x+y) = f(x) + f(y)\")\n",
    "print(f\"{f(x+y)}\")\n",
    "print(f\"f(x):\\n {f(x)}\")\n",
    "print(f\"f(y):\\n {f(y)}\")\n",
    "# Imprimir bonito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6c26e-c4b0-4d73-9756-12c93519a37a",
   "metadata": {},
   "source": [
    "#### Operaciones sobre vectores y matrices\n",
    "\n",
    "- Las matrices son funciones que transforman nuestros vectores, son mapas lineales. Una matriz $A\\in \\mathbb{R}^{m\\times n}$ transforma un vector $\\mathbf{x}\\in \\mathbb{R}^{n}$ a un nuevo vector $\\mathbf{y} \\in  \\mathbb{R}^{m}$ a través de la operación $M\\mathbf{x}$ llamada producto matriz vector.\n",
    "- Las matrices ademas contienen información de nuestros datos (mas adelante veremos como los datos son representados en la matriz)\n",
    "- Existen maneras de caracterizar las matrices para medir la cantidad de información que poseen:\n",
    "    - Tamaño: Se mide a traves de la norma matricial.\n",
    "    - Cantidad de información: Se puede tener una nocion de la cantidad de información contando la cantidad de auto valores diferentes de cero.\n",
    "    - ¿Cómo una matriz transforma un vector?: se puede saber como una matriz estire/comprime o rota a un vector a traves de sus espacios fundamentales (SVD)\n",
    " \n",
    "Por ahora nos interesa entender como se hacen las operaciones fundamentales entre vectores y matrices:\n",
    "1. Suma de matrices\n",
    "2. Suma de vectores\n",
    "3. Multiplicar matriz por escalar\n",
    "4. Multiplicar vector por escalar\n",
    "5. Producto interno entre vectores\n",
    "6. Producto matriz/vector\n",
    "7. Producto de matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5ff43",
   "metadata": {},
   "source": [
    "## Operaciones fundamentales\n",
    "\n",
    "1. Suma de matrices: la suma de matrices se realiza componente a componente para matrices de dimension $\\mathbb{R}^{m\\times n}$. Es decir, dadas las matrices $A$ y $B\\in \\mathbb{R}^{m \\times n}$ donde $A = a_{ij}$, $B = b_{ij}$ con $i=1,\\dots,m$ y $j=1,\\dots,m$ son las componentes, la suma es dada por: \n",
    "\\begin{equation*}\n",
    "A + B = a_{ij}+b_{ij}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ac8f3f-4a7d-4498-8964-d8af30dfb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) #reproducibilidad del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df5038b-ba34-4356-80ac-6eb74978423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3\n",
    "n = 2\n",
    "A = np.random.randint(0,10,(m,n))\n",
    "B = np.random.randint(0,10,(m,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d30b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 9],\n",
       "       [3, 5],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "452bf2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 6],\n",
       "       [8, 8],\n",
       "       [1, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ebec35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 15],\n",
       "       [11, 13],\n",
       "       [ 3, 10]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "521a52c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3],\n",
       "       [-5, -3],\n",
       "       [ 1, -2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A-B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03331ed1",
   "metadata": {},
   "source": [
    "2. Suma de vectores: La lógica de suma es análoga para vectores (sean filas o columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c31d24da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector a: [[7 7]]\n",
      "vector a: [[8 1]]\n",
      "vector a+b: [[15  8]]\n",
      "vector a-b: [[-1  6]]\n"
     ]
    }
   ],
   "source": [
    "# Vectores fila\n",
    "n = 2\n",
    "a = np.random.randint(0,10,(1,n))\n",
    "b = np.random.randint(0,10,(1,n))\n",
    "\n",
    "print(f\"vector a: {a}\")\n",
    "print(f\"vector a: {b}\")\n",
    "print(f\"vector a+b: {a+b}\")\n",
    "print(f\"vector a-b: {a-b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80546ee0",
   "metadata": {},
   "source": [
    "3-4. Multiplicación matriz por escalar o vector por escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15b49f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 27],\n",
       "       [ 9, 15],\n",
       "       [ 6, 12]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 3\n",
    "3*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d8a46aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 21]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha*a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e8436",
   "metadata": {},
   "source": [
    "5. Producto interno\n",
    "\n",
    "Dentro de un espacio vectorial un producto interno es una función o mapa definido como:\n",
    "\n",
    "\\begin{align*}\n",
    "\\langle \\cdot, \\cdot\\rangle :&  U\\times U \\rightarrow \\mathbb{K}\\\\\n",
    "& (\\mathbf{x},\\mathbf{y}) \\rightarrow a = \\langle \\mathbf{x},\\mathbf{y} \\rangle\n",
    "\\end{align*}\n",
    "\n",
    "donde $\\mathbb{K}$ es un cuerpo sobre el que está definido. Es decir, la función toma un par de vectores y los convierte en un solo número real.\n",
    "Esta operación permitirá comparar vectores o saber si son perpendiculares. También permite crear nuevas funciones, por ejemplo ```proyectores```.\n",
    "\n",
    "Para fines de este curso $\\mathbb{K} = \\mathbb{R}$. Dados $\\mathbf{x}$,$\\mathbf{y}$,$\\mathbf{z}\\in U$ algunas propiedades del producto interno: \n",
    "\n",
    "- Linealidad: $ \\langle \\alpha \\cdot \\mathbf{x} + \\beta \\cdot \\mathbf{y}, \\mathbf{z} \\rangle = \\alpha \\cdot\\langle \\mathbf{x}, \\mathbf{z} \\rangle + \\beta \\cdot \\langle \\mathbf{y}, \\mathbf{z} \\rangle$ con $\\alpha$, $\\beta \\in \\mathbb{R}$\n",
    "\n",
    "- Hermiticidad: $\\langle \\mathbf{x},\\mathbf{y} \\rangle = \\langle \\mathbf{y},\\mathbf{x} \\rangle$\n",
    "\n",
    "- Definida positiva: $\\langle \\mathbf{x},\\mathbf{x} \\rangle \\geq 0$ y $\\langle \\mathbf{x},\\mathbf{x} \\rangle = 0 $, si y solo si $\\mathbf{x}= 0$\n",
    "\n",
    "Estas propiedades son fundamentales para enteneder conceptos relacionados a similaridad, producto de matrices y tamaño de vectores. La información que trabajemos a futuro para entrenar nuestros modelos se representará a través de vectores y matrices, siendo la operación ```producto punto``` un tipo de producto interno que cumple con las propiedades anteriores y que usaremos para operar tanto en redes neuronales como otros modelos.\n",
    "\n",
    "El producto punto es definido para el caso de vectores en $\\mathbb{R}^{n}$ de la siguiente forma:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\langle \\mathbf{a}, \\mathbf{b} \\rangle = \\sum_{i=1}^{n} a_i b_i\n",
    "\\end{equation}\n",
    "\n",
    "**Ejemplo** \n",
    "\n",
    "Dados los vectores:\n",
    "\n",
    "$\n",
    "\\mathbf{a} = \n",
    "\\begin{pmatrix}\n",
    "a_1 \\\\\n",
    "a_2 \\\\\n",
    "a_3\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "\\mathbf{b} = \n",
    "\\begin{pmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "b_3\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "Calculamos el producto interno de la siguiente forma: \n",
    "\n",
    "$\\langle \\mathbf{a}, \\mathbf{b} \\rangle = a_1 \\cdot b_1 + a_2 \\cdot b_2 + a_3 \\cdot b_3$\n",
    "\n",
    "En forma vectorial\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "a_1 & a_2 & a_3\n",
    "\\end{pmatrix}_{1\\times 3}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "b_3\n",
    "\\end{pmatrix}_{3\\times 1}= (a_1b_1 + a_2b_2 + a_3b_3)_{1\\times 1}$\n",
    "\n",
    "Observe que las dimensiones \"externas\" de cada vector, en este caso 1, determinan la dimensión final que en este caso es un escalar $1\\times 1 = 1$ este solo posee una dimensión. Las dimensiones \"internas\" dadas por 3 deben coincidir para poder operar los vectores. Veamos algunos ejemplos en ```numpy``` para observar tanto el caso correcto de uso como el caso que puede dar error. Este tipo de error es común al momento de construir modelos desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7806ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector a: [[3 7]] con dimensión (1, 2)\n",
      "vector a: [[0 1]] con dimensión (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Vectores fila\n",
    "n = 2\n",
    "a = np.random.randint(0,10,(1,n))\n",
    "b = np.random.randint(0,10,(1,n))\n",
    "\n",
    "print(f\"vector a: {a} con dimensión {a.shape}\")\n",
    "print(f\"vector a: {b} con dimensión {b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c17fbd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector a*b: [[7]] con dimensión (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"vector a*b: {np.dot(a,b.T)} con dimensión {np.dot(a,b.T).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfbeb21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector a*b: [[7]] con dimensión (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"vector a*b: {a@b.T} con dimensión {(a@b.T).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca866bb0",
   "metadata": {},
   "source": [
    "Uso incorrecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "886b464d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/rodolfolobocarrasco/Desktop/DeepLearning/deep-learning-course/01-regresion-lineal.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rodolfolobocarrasco/Desktop/DeepLearning/deep-learning-course/01-regresion-lineal.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvector a*b: \u001b[39m\u001b[39m{\u001b[39;00ma\u001b[39m@b\u001b[39;49m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)"
     ]
    }
   ],
   "source": [
    "print(f\"vector a*b: {a@b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f56f812e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/rodolfolobocarrasco/Desktop/DeepLearning/deep-learning-course/01-regresion-lineal.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rodolfolobocarrasco/Desktop/DeepLearning/deep-learning-course/01-regresion-lineal.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvector a*b: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39;49mdot(a,b)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "print(f\"vector a*b: {np.dot(a,b)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d530e6d",
   "metadata": {},
   "source": [
    "El producto interno puede interpretarse geométricamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f423ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
